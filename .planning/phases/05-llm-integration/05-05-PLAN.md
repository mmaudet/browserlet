---
phase: 05-llm-integration
plan: 05
type: execute
wave: 4
depends_on: ["05-04"]
files_modified:
  - entrypoints/sidepanel/main.ts
  - entrypoints/sidepanel/router.ts
  - entrypoints/sidepanel/components/RecordingView.ts
  - public/_locales/en/messages.json
  - public/_locales/fr/messages.json
autonomous: false

must_haves:
  truths:
    - "Settings view is accessible from sidepanel navigation"
    - "Recording stop triggers BSL generation via LLM"
    - "Generated BSL is saved as a new script"
    - "UI shows whether LLM was used or fallback"
  artifacts:
    - path: "entrypoints/sidepanel/main.ts"
      provides: "Settings view integration"
      contains: "LLMSettings"
    - path: "entrypoints/sidepanel/components/RecordingView.ts"
      provides: "BSL generation on stop"
      contains: "GENERATE_BSL"
  key_links:
    - from: "entrypoints/sidepanel/components/RecordingView.ts"
      to: "entrypoints/background/messaging.ts"
      via: "chrome.runtime.sendMessage GENERATE_BSL"
      pattern: "sendMessage.*GENERATE_BSL"
    - from: "entrypoints/sidepanel/main.ts"
      to: "entrypoints/sidepanel/components/LLMSettings.ts"
      via: "Settings view renders LLMSettings"
      pattern: "LLMSettings"
---

<objective>
Integrate LLM settings into sidepanel navigation and wire recording stop to BSL generation.

Purpose: Complete the user flow - user can configure LLM in settings, then record actions, and get LLM-enhanced BSL scripts automatically generated.
Output: Working end-to-end flow from settings configuration to BSL script generation.
</objective>

<execution_context>
@/Users/mmaudet/.claude/get-shit-done/workflows/execute-plan.md
@/Users/mmaudet/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/05-llm-integration/05-RESEARCH.md

# Files to modify
@entrypoints/sidepanel/main.ts
@entrypoints/sidepanel/router.ts
@entrypoints/sidepanel/components/RecordingView.ts
@entrypoints/sidepanel/stores/scripts.ts
@public/_locales/en/messages.json
@public/_locales/fr/messages.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Settings view to sidepanel navigation</name>
  <files>entrypoints/sidepanel/main.ts, entrypoints/sidepanel/router.ts</files>
  <action>
Add Settings view to the sidepanel navigation.

**router.ts:**
Add 'settings' to the view type:
```typescript
export type View = 'list' | 'editor' | 'run' | 'record' | 'settings';
```

**main.ts:**
Import LLMSettings component and loadLLMConfig from stores.

Add settings view rendering in the view switch:
```typescript
case 'settings':
  return LLMSettings();
```

Add settings navigation button to the header/nav area:
- Icon: gear/cog icon (can use unicode or simple text)
- onClick: () => currentView.val = 'settings'
- Add i18n key for "Settings"

On sidepanel load (in initialization):
- Call loadLLMConfig() to restore config from storage
- If config needs API key (after browser restart), show notification

Add "Back" navigation from settings view to previous view.
  </action>
  <verify>npm run dev - open sidepanel, verify Settings button appears and opens settings view</verify>
  <done>Settings view accessible from sidepanel navigation with back button</done>
</task>

<task type="auto">
  <name>Task 2: Wire recording stop to BSL generation</name>
  <files>entrypoints/sidepanel/components/RecordingView.ts</files>
  <action>
Modify RecordingView to generate BSL when recording stops.

Import:
- getLLMConfigForServiceWorker, llmConfigStore from '../stores/llmConfig'

Modify the stop recording flow:

1. After STOP_RECORDING message succeeds and actions are retrieved:

2. Check if LLM is configured (llmConfigStore.isConfigured.val):
   - If yes: Send GENERATE_BSL message with actions
   - If no: Generate basic BSL locally using fallback approach

3. On GENERATE_BSL response:
   - Show loading state while waiting
   - result contains { bsl: string, usedLLM: boolean }
   - If usedLLM is false, show subtle indicator "Generated without LLM"

4. Create new script with generated BSL:
   - Generate script ID with crypto.randomUUID()
   - Create Script object with name based on timestamp or first action URL
   - Save to scripts store
   - Navigate to editor view with new script

5. Error handling:
   - If GENERATE_BSL fails, fall back to basic generation
   - Show error notification but don't block workflow
   - Still save the basic script

Add loading indicator during BSL generation (can take 2-10 seconds with Claude).
  </action>
  <verify>npm run dev - record some actions, stop recording, verify BSL script is generated and saved</verify>
  <done>Recording stop triggers GENERATE_BSL, creates script, and navigates to editor</done>
</task>

<task type="auto">
  <name>Task 3: Add i18n strings for LLM features</name>
  <files>public/_locales/en/messages.json, public/_locales/fr/messages.json</files>
  <action>
Add all necessary i18n strings for Phase 5 features.

**English (messages.json):**
```json
{
  "settingsTitle": { "message": "Settings" },
  "settingsLLM": { "message": "LLM Configuration" },
  "providerLabel": { "message": "Provider" },
  "providerClaude": { "message": "Claude API (Anthropic)" },
  "providerOllama": { "message": "Ollama (Local)" },
  "apiKeyLabel": { "message": "API Key" },
  "apiKeyPlaceholder": { "message": "Enter your Anthropic API key" },
  "apiKeyRequired": { "message": "API key required (re-enter after browser restart)" },
  "modelLabel": { "message": "Model" },
  "ollamaHostLabel": { "message": "Ollama Host" },
  "ollamaModelLabel": { "message": "Model Name" },
  "testConnection": { "message": "Test Connection" },
  "connectionSuccess": { "message": "Connected successfully" },
  "connectionFailed": { "message": "Connection failed" },
  "saveSettings": { "message": "Save Settings" },
  "settingsSaved": { "message": "Settings saved" },
  "generatingBSL": { "message": "Generating script..." },
  "generatedWithLLM": { "message": "Generated with LLM" },
  "generatedBasic": { "message": "Generated (basic mode)" },
  "llmNotConfigured": { "message": "LLM not configured - using basic generation" }
}
```

**French (messages.json):**
```json
{
  "settingsTitle": { "message": "Parametres" },
  "settingsLLM": { "message": "Configuration LLM" },
  "providerLabel": { "message": "Fournisseur" },
  "providerClaude": { "message": "Claude API (Anthropic)" },
  "providerOllama": { "message": "Ollama (Local)" },
  "apiKeyLabel": { "message": "Cle API" },
  "apiKeyPlaceholder": { "message": "Entrez votre cle API Anthropic" },
  "apiKeyRequired": { "message": "Cle API requise (a ressaisir apres redemarrage)" },
  "modelLabel": { "message": "Modele" },
  "ollamaHostLabel": { "message": "Hote Ollama" },
  "ollamaModelLabel": { "message": "Nom du modele" },
  "testConnection": { "message": "Tester la connexion" },
  "connectionSuccess": { "message": "Connecte avec succes" },
  "connectionFailed": { "message": "Echec de connexion" },
  "saveSettings": { "message": "Enregistrer" },
  "settingsSaved": { "message": "Parametres enregistres" },
  "generatingBSL": { "message": "Generation du script..." },
  "generatedWithLLM": { "message": "Genere avec LLM" },
  "generatedBasic": { "message": "Genere (mode basique)" },
  "llmNotConfigured": { "message": "LLM non configure - generation basique" }
}
```

Merge these into existing messages.json files (don't overwrite existing keys).
  </action>
  <verify>npm run build - verify no missing i18n keys in console warnings</verify>
  <done>All LLM-related strings available in EN and FR</done>
</task>

</tasks>

<verification>
1. npm run build completes without errors
2. Settings accessible from sidepanel
3. Recording -> Stop generates BSL and creates script
4. i18n strings work in both languages
</verification>

<success_criteria>
- Settings view shows LLM configuration UI
- Recording stop triggers BSL generation via service worker
- Generated script saved to storage and opened in editor
- UI indicates whether LLM or fallback was used
- All text internationalized in EN/FR
</success_criteria>

<checkpoint type="human-verify" gate="blocking">
  <what-built>Complete LLM integration: settings UI, BSL generation on recording stop, script creation</what-built>
  <how-to-verify>
    1. Open sidepanel, click Settings
    2. Select provider (Claude or Ollama)
    3. If Claude: enter API key, select model, save
    4. If Ollama: ensure Ollama is running, test connection, save
    5. Go to Recording view, record 2-3 actions on any page
    6. Stop recording
    7. Verify loading indicator appears
    8. Verify script is generated and editor opens with BSL
    9. Check if "Generated with LLM" or "Generated (basic mode)" indicator shows
    10. Test fallback: remove API key, record again, should still generate basic BSL
  </how-to-verify>
  <resume-signal>Type "approved" if all flows work, or describe issues</resume-signal>
</checkpoint>

<output>
After completion, create `.planning/phases/05-llm-integration/05-05-SUMMARY.md`
</output>
